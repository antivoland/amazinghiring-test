# Транслитерация слов

> Нужно сделать транлитератор имен и фамилий с русского на английский и обратно. Например, Петров должен траслитерироваться в Petrov, Petroff,... Или наоборот, с английского Jurij переводится в Юрий. Файлы с таблицей траслитерации и с частотами имен/фамилий приложены к письму.
> 
> Хотелось бы, чтоб программа не выдавала заранее несуществующих имен и фамилий. Например, для имени Инесса не было бы варианта Inesssa. И работала на не знакомых словах которых нет в файле со статистикой.

## Решение

Для начала выделим отдельные N-граммы из слов частотного словаря. При этом количество слогов будет переменным: N слогов будет браться из середины слова и N-1, N-2,..1 с краёв. Все возможные слоги содержатся в словаре транлитерации [translit.txt](src/test/resources/translit.txt).

Рассмотрим случай с N = 3. Разбиение на слоги будем осуществлять всеми возможными способами. Например, имя `алекс` может быть представлено как `а` + `л` + `е` + `к` + `с`, равно как и `а` + `л` + `е` + `кс`. При этом в первом случае выбираются N-граммы `а`, `а+л`, `а+л+е`, `л+е+к`, `е+к+с`, `к+с` и `с`, во втором же случае образуется набор `а`, `а+л`, `а+л+е`, `л+е+кс`, `е+кс` и `кс`. Частотой появления N-граммы для данного слова положим отношение частоты самого слова, возведённую в некоторую степень FP, чтобы усилить правдоподобие наиболее частых слов, к количеству вариантов разбиения на слоги. Для выбранного выше имени частота WF составляет 21465, вариантов два, и результатом будет частотный словарик:

```
(а, MIDDLE) -> 460746225 (WF^FP)
(а+л, MIDDLE) -> 460746225 (WF^FP)
(а+л+е, MIDDLE) -> 460746225 (WF^FP)
(л+е+к, MIDDLE) -> 230373112,5 (WF^FP/2)
(е+к+с, MIDDLE) -> 230373112,5 (WF^FP/2)
(к+с, RIGHT) -> 230373112,5 (WF^FP/2)
(с, RIGHT) -> 230373112,5 (WF^FP/2)
(л+е+кс, MIDDLE) -> 230373112,5 (WF^FP/2)
(е+кс, RIGHT) -> 230373112,5 (WF^FP/2)
(кс, RIGHT) -> 230373112,5 (WF^FP/2)
```

Здесь `MIDDLE` и `RIGHT` означают позицию N-граммы в слове.

Применим это разбиение и заданный расчёт частоты для остальных слов для каждого из алфавитов и просуммируем частоты соответствующих N-грамм (соответствует последовательность слогов и позиция в слове). Полученные частотные словари N-грамм применим далее для расчёта вероятности существования слова для заданного алфавита.

Показатель правдоподобия или вероятность существования слова длины m определим как P(S<sub>1</sub>..S<sub>m</sub>) = P(S<sub>1</sub>, MIDDLE) * P(S<sub>2</sub>|S<sub>1</sub>, MIDDLE) * P(S<sub>3</sub>|S<sub>2</sub>, S<sub>1</sub>, MIDDLE) * ... * P(S<sub>m</sub>|S<sub>m-1</sub>, S<sub>m-2</sub>, MIDDLE) * P(S<sub>m-1</sub>|S<sub>m-2</sub>, RIGHT) * P(S<sub>m-2</sub>|RIGHT), где P(S<sub>1</sub>, MIDDLE) — доля присутствия слога S в начале слова <sub>1</sub> в частотном словаре, P(S<sub>2</sub>|S<sub>1</sub>, MIDDLE) — доля присутствия биграммы S<sub>1</sub>S<sub>2</sub> в начале слова и т.д. Под долей присутствия я подразумеваю отношение частоты появления N-граммы в заданной позиции (середина или конец слова) к сумме всех соответствующих частот.

Осталось непосредственно произвести транслитерацию. Для этого для каждого из возможных разбиений входного слова I<sub>1</sub>..I<sub>k</sub> подберём все возможные варианты транслитераций O<sub>1</sub>..O<sub>k</sub> и выберем пару, для которой совместная вероятность существования в соответствующих словарях максимальна, то есть выясним argmax<sub>I,O</sub> P(I) * R<sub>in</sub> + P(O) * R<sub>out</sub>. Дополнительные параметры R<sub>in</sub> и R<sub>out</sub> — автоматически выбранные доли доверия к словарям.

Пример использования можно найти в классе [TransliteratorTest](src/test/java/antivoland/amahir/translit/ngram/TransliteratorTest.java). Частотный словарь я сократил до 300000 первых строк, поскольку больше в память не помещалось:
 
```
¯\_(ツ)_/¯
```

Текущий вывод выглядит следующим образом:

```
LA-RU: model -> {outputCorpusForecaster={N=3, epsilon=1.2629363628365553E-11}, forecastStrategy={inputRate=0.6, outputRate=0.4}, seekHiddenInputs=true}
RU-LA: model -> {outputCorpusForecaster={N=3, epsilon=6.081369911943951E-13}, forecastStrategy={inputRate=0.9999999999999999, outputRate=1.1102230246251565E-16}, seekHiddenInputs=false}

Transliterating known latin names
LA-RU: elena -> елена (елена, 0)
LA-RU: dmitrij -> дмитрий (дмитрий, 0)
LA-RU: olga -> ольга (ольга, 0)
LA-RU: jurij -> юрий (юрий, 0)
LA-RU: alexey -> алексей (алексей, 0)
LA-RU: tatyana -> татьяна (татьяна, 0)
LA-RU: petroff -> петров (петров, 0)
LA-RU: sergey -> сергей (сергей, 0)
LA-RU: inessa -> инеся (инесса, 2)
LA-RU: andrey -> андрей (андрей, 0)
LA-RU: alexandr -> александр (александр, 0)
LA-RU: irina -> ирина (ирина, 0)

Transliterating unknown latin names
LA-RU: plakilla -> плакилла (плакилла, 0)
LA-RU: epiktet -> епиктет (эпиктет, 1)
LA-RU: avundiy -> авундий (авундий, 0)
LA-RU: feognia -> феогния (феогния, 0)
LA-RU: usfazan -> юсфазан (усфазан, 1)

Transliterating known russian names
RU-LA: ирина -> irina (irina, 0)
RU-LA: татьяна -> tatjana (tatyana, 1)
RU-LA: андрей -> andre (andrey, 1)
RU-LA: петров -> petrov (petrov, 0)
RU-LA: инесса -> inessa (inessa, 0)
RU-LA: юрий -> jury (jurij, 2)
RU-LA: дмитрий -> dmitry (dmitrij, 2)
RU-LA: елена -> elena (elena, 0)
RU-LA: ольга -> olga (olga, 0)
RU-LA: алексей -> alexe (alexey, 1)
RU-LA: сергей -> serge (sergey, 1)

Transliterating unknown russian names
RU-LA: плакилла -> placilla (plakilla, 1)
RU-LA: авундий -> avyndiy (avundiy, 1)
RU-LA: усфазан -> usfasan (usfazan, 1)
RU-LA: феогния -> feognia (feognia, 0)
RU-LA: эпиктет -> epiktet (epiktet, 0)
```

Тут представлены входные и транслитерированные слова, в скобках же указаны ожидаемые транслитерирации и расстояния Левенштейна между ними и фактическими значениями. Как видно, модель также умеет искать некоторые скрытые символы.

Можно разработать инструмент для определения оптимального количества слогов в N-грамме и степень, в которую следует возводить частоты слов. Триграммы подходят, казалось бы, оптимально, а степень я пока оставил вторую.
